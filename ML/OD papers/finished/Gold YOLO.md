---
annotation-target: https://arxiv.org/pdf/2309.11331.pdf
---


>%%
>```annotation-json
>{"created":"2025-02-04T00:09:11.822Z","text":"Note that was done before RT-DETR and D-FINE were released","updated":"2025-02-04T00:09:11.822Z","document":{"title":"2309.11331v5.pdf","link":[{"href":"urn:x-pdf:950b1c33809ea8c56afa8e7d6f678701"},{"href":"https://arxiv.org/pdf/2309.11331.pdf"}],"documentFingerprint":"950b1c33809ea8c56afa8e7d6f678701"},"uri":"https://arxiv.org/pdf/2309.11331.pdf","target":[{"source":"https://arxiv.org/pdf/2309.11331.pdf","selector":[{"type":"TextPositionSelector","start":4417,"end":4506},{"type":"TextQuoteSelector","exact":"Small-scale object detection modelsbased on CNN still dominate the speed-accuracy trade-o","prefix":" the speed of CNN-based models. ","suffix":"ff, such as YOLOX [11] and YOLOv"}]}]}
>```
>%%
>*%%PREFIX%%the speed of CNN-based models.%%HIGHLIGHT%% ==Small-scale object detection modelsbased on CNN still dominate the speed-accuracy trade-o== %%POSTFIX%%ff, such as YOLOX [11] and YOLOv*
>%%LINK%%[[#^kpj75azutfa|show annotation]]
>%%COMMENT%%
>Note that was done before RT-DETR and D-FINE were released
>%%TAGS%%
>
^kpj75azutfa


>%%
>```annotation-json
>{"created":"2025-02-04T00:09:42.819Z","updated":"2025-02-04T00:09:42.819Z","document":{"title":"2309.11331v5.pdf","link":[{"href":"urn:x-pdf:950b1c33809ea8c56afa8e7d6f678701"},{"href":"https://arxiv.org/pdf/2309.11331.pdf"}],"documentFingerprint":"950b1c33809ea8c56afa8e7d6f678701"},"uri":"https://arxiv.org/pdf/2309.11331.pdf","target":[{"source":"https://arxiv.org/pdf/2309.11331.pdf","selector":[{"type":"TextPositionSelector","start":4714,"end":4737},{"type":"TextQuoteSelector","exact":"ackbone, neck, and head","prefix":"ectors consist of three parts: b","suffix":". The backbonearchitecture has b"}]}]}
>```
>%%
>*%%PREFIX%%ectors consist of three parts: b%%HIGHLIGHT%% ==ackbone, neck, and head== %%POSTFIX%%. The backbonearchitecture has b*
>%%LINK%%[[#^bcsuzhj2jci|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^bcsuzhj2jci


>%%
>```annotation-json
>{"created":"2025-02-04T00:10:48.322Z","text":"basis of the model, YOLO with Gather-And-Dsitributed (GD)","updated":"2025-02-04T00:10:48.322Z","document":{"title":"2309.11331v5.pdf","link":[{"href":"urn:x-pdf:950b1c33809ea8c56afa8e7d6f678701"},{"href":"https://arxiv.org/pdf/2309.11331.pdf"}],"documentFingerprint":"950b1c33809ea8c56afa8e7d6f678701"},"uri":"https://arxiv.org/pdf/2309.11331.pdf","target":[{"source":"https://arxiv.org/pdf/2309.11331.pdf","selector":[{"type":"TextPositionSelector","start":5615,"end":5981},{"type":"TextQuoteSelector","exact":" a novel Gather-and-Distribute mechanism (GD) for efficient information exchangingin YOLOs by globally fusing multi-level features and injecting the global information into higherlevels. This significantly enhances the information fusion capability of the neck without significantlyincreasing the latency, improving the model’s performance across varying object size","prefix":"on of TopFormer’stheory, propose","suffix":"s. Specifically,GD mechanism com"}]}]}
>```
>%%
>*%%PREFIX%%on of TopFormer’stheory, propose%%HIGHLIGHT%% ==a novel Gather-and-Distribute mechanism (GD) for efficient information exchangingin YOLOs by globally fusing multi-level features and injecting the global information into higherlevels. This significantly enhances the information fusion capability of the neck without significantlyincreasing the latency, improving the model’s performance across varying object size== %%POSTFIX%%s. Specifically,GD mechanism com*
>%%LINK%%[[#^7zafvwhfnzh|show annotation]]
>%%COMMENT%%
>basis of the model, YOLO with Gather-And-Dsitributed (GD)
>%%TAGS%%
>
^7zafvwhfnzh


>%%
>```annotation-json
>{"created":"2025-02-04T00:12:49.795Z","text":"Short YOLO history:\nv1-v3: single state detections models with backbone-neck-head, works on different sizes thruugh mutli-scale branches\nV4: uses Mish activation, PANet and data augmentations\nV5: improves data augemtntation method and has mutliple versions\nX: Multi-positive, ahnchor-free, and decoupeld head into the model\nv6: repareamertization method to yolo, using EfficientREp Backbone and Rep-PAN neck\nv7: implements E-ELAN for gradient paths improvement\nV8: integrates all of them into a SOTA model","updated":"2025-02-04T00:12:49.795Z","document":{"title":"2309.11331v5.pdf","link":[{"href":"urn:x-pdf:950b1c33809ea8c56afa8e7d6f678701"},{"href":"https://arxiv.org/pdf/2309.11331.pdf"}],"documentFingerprint":"950b1c33809ea8c56afa8e7d6f678701"},"uri":"https://arxiv.org/pdf/2309.11331.pdf","target":[{"source":"https://arxiv.org/pdf/2309.11331.pdf","selector":[{"type":"TextPositionSelector","start":6917,"end":6943},{"type":"TextQuoteSelector","exact":"Real-time object detectors","prefix":"similarspeed.2 Related works2.1 ","suffix":"After years of development, the "}]}]}
>```
>%%
>*%%PREFIX%%similarspeed.2 Related works2.1%%HIGHLIGHT%% ==Real-time object detectors== %%POSTFIX%%After years of development, the*
>%%LINK%%[[#^0x2rf1221w6|show annotation]]
>%%COMMENT%%
>Short YOLO history:
>v1-v3: single state detections models with backbone-neck-head, works on different sizes thruugh mutli-scale branches
>V4: uses Mish activation, PANet and data augmentations
>V5: improves data augemtntation method and has mutliple versions
>X: Multi-positive, ahnchor-free, and decoupeld head into the model
>v6: repareamertization method to yolo, using EfficientREp Backbone and Rep-PAN neck
>v7: implements E-ELAN for gradient paths improvement
>V8: integrates all of them into a SOTA model
>%%TAGS%%
>
^0x2rf1221w6


>%%
>```annotation-json
>{"created":"2025-02-04T05:49:59.501Z","updated":"2025-02-04T05:49:59.501Z","document":{"title":"2309.11331v5.pdf","link":[{"href":"urn:x-pdf:950b1c33809ea8c56afa8e7d6f678701"},{"href":"https://arxiv.org/pdf/2309.11331.pdf"}],"documentFingerprint":"950b1c33809ea8c56afa8e7d6f678701"},"uri":"https://arxiv.org/pdf/2309.11331.pdf","target":[{"source":"https://arxiv.org/pdf/2309.11331.pdf","selector":[{"type":"TextPositionSelector","start":10090,"end":10291},{"type":"TextQuoteSelector","exact":"FPN provides an efficientarchitectural design for fusing multi-scale features through cross-scale connections and informationexchange, thereby boosting the detection accuracy of objects of varied sizes","prefix":"ance through mutual assistance. ","suffix":".Based on FPN, the Path Aggregat"}]}]}
>```
>%%
>*%%PREFIX%%ance through mutual assistance.%%HIGHLIGHT%% ==FPN provides an efficientarchitectural design for fusing multi-scale features through cross-scale connections and informationexchange, thereby boosting the detection accuracy of objects of varied sizes== %%POSTFIX%%.Based on FPN, the Path Aggregat*
>%%LINK%%[[#^hh38imrl2ae|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^hh38imrl2ae


>%%
>```annotation-json
>{"created":"2025-02-04T05:50:27.304Z","updated":"2025-02-04T05:50:27.304Z","document":{"title":"2309.11331v5.pdf","link":[{"href":"urn:x-pdf:950b1c33809ea8c56afa8e7d6f678701"},{"href":"https://arxiv.org/pdf/2309.11331.pdf"}],"documentFingerprint":"950b1c33809ea8c56afa8e7d6f678701"},"uri":"https://arxiv.org/pdf/2309.11331.pdf","target":[{"source":"https://arxiv.org/pdf/2309.11331.pdf","selector":[{"type":"TextPositionSelector","start":10310,"end":10441},{"type":"TextQuoteSelector","exact":"Path Aggregation Network (PANet) [49] incorporates a bottom-up path to makeinformation fusion between different levels more adequat","prefix":" varied sizes.Based on FPN, the ","suffix":"e.Similarly, EfficientDet [44] p"}]}]}
>```
>%%
>*%%PREFIX%%varied sizes.Based on FPN, the%%HIGHLIGHT%% ==Path Aggregation Network (PANet) [49] incorporates a bottom-up path to makeinformation fusion between different levels more adequat== %%POSTFIX%%e.Similarly, EfficientDet [44] p*
>%%LINK%%[[#^4ye002jyf1w|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^4ye002jyf1w


>%%
>```annotation-json
>{"created":"2025-02-04T05:54:11.272Z","text":"in a FPN, you must convert the other levels into a dimensionality of your desired level or middleground, and you do this pairwise each time, so you lose a lot of information","updated":"2025-02-04T05:54:11.272Z","document":{"title":"2309.11331v5.pdf","link":[{"href":"urn:x-pdf:950b1c33809ea8c56afa8e7d6f678701"},{"href":"https://arxiv.org/pdf/2309.11331.pdf"}],"documentFingerprint":"950b1c33809ea8c56afa8e7d6f678701"},"uri":"https://arxiv.org/pdf/2309.11331.pdf","target":[{"source":"https://arxiv.org/pdf/2309.11331.pdf","selector":[{"type":"TextPositionSelector","start":13230,"end":13315},{"type":"TextQuoteSelector","exact":"This transfer mode can result in a significant loss of information during calculation","prefix":"y combining level-2 information.","suffix":". Informationinteractions betwee"}]}]}
>```
>%%
>*%%PREFIX%%y combining level-2 information.%%HIGHLIGHT%% ==This transfer mode can result in a significant loss of information during calculation== %%POSTFIX%%. Informationinteractions betwee*
>%%LINK%%[[#^8zb9xbdj5vl|show annotation]]
>%%COMMENT%%
>in a FPN, you must convert the other levels into a dimensionality of your desired level or middleground, and you do this pairwise each time, so you lose a lot of information
>%%TAGS%%
>
^8zb9xbdj5vl


>%%
>```annotation-json
>{"created":"2025-02-04T05:55:15.642Z","updated":"2025-02-04T05:55:15.642Z","document":{"title":"2309.11331v5.pdf","link":[{"href":"urn:x-pdf:950b1c33809ea8c56afa8e7d6f678701"},{"href":"https://arxiv.org/pdf/2309.11331.pdf"}],"documentFingerprint":"950b1c33809ea8c56afa8e7d6f678701"},"uri":"https://arxiv.org/pdf/2309.11331.pdf","target":[{"source":"https://arxiv.org/pdf/2309.11331.pdf","selector":[{"type":"TextPositionSelector","start":13922,"end":14236},{"type":"TextQuoteSelector","exact":"By usinga unified module to gather and fuse information from all levels and subsequently distribute it todifferent levels, we not only avoid the loss of information inherent in the traditional FPN structure butalso enhance the neck’s partial information fusion capabilities without significantly increasing latency","prefix":"-and-distribute mechanism (GD). ","suffix":".Our approach thus allows for mo"}]}]}
>```
>%%
>*%%PREFIX%%-and-distribute mechanism (GD).%%HIGHLIGHT%% ==By usinga unified module to gather and fuse information from all levels and subsequently distribute it todifferent levels, we not only avoid the loss of information inherent in the traditional FPN structure butalso enhance the neck’s partial information fusion capabilities without significantly increasing latency== %%POSTFIX%%.Our approach thus allows for mo*
>%%LINK%%[[#^9fftopkiymi|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^9fftopkiymi


>%%
>```annotation-json
>{"created":"2025-02-04T05:57:13.837Z","text":"GD uses 3 modules. \nFeature Alignment Module (FAM), Information Fusion Module (IFM), and Information INjection Model (inject)\n\nGathering processes: FAM collects and aligns features from various levels. IFM fueses these aligned featuers to generate global information\n\nInjection module distributes infroation across each level and injects it using attention operations","updated":"2025-02-04T05:57:13.837Z","document":{"title":"2309.11331v5.pdf","link":[{"href":"urn:x-pdf:950b1c33809ea8c56afa8e7d6f678701"},{"href":"https://arxiv.org/pdf/2309.11331.pdf"}],"documentFingerprint":"950b1c33809ea8c56afa8e7d6f678701"},"uri":"https://arxiv.org/pdf/2309.11331.pdf","target":[{"source":"https://arxiv.org/pdf/2309.11331.pdf","selector":[{"type":"TextPositionSelector","start":14411,"end":15021},{"type":"TextQuoteSelector","exact":"In our implementation, the process gather and distribute correspond to three modules: FeatureAlignment Module (FAM), Information Fusion Module (IFM), and Information Injection Module(Inject).• The gather process involves two steps. Firstly, the FAM collects and aligns features fromvarious levels. Secondly, IFM fuses the aligned features to generate global information.• Upon obtaining the fused global information from the gather process, the inject moduledistribute this information across each level and injects it using simple attention operations,subsequently enhancing the branch’s detection capability.","prefix":"g backbone-neck-head structure.4","suffix":"To enhance the model’s ability t"}]}]}
>```
>%%
>*%%PREFIX%%g backbone-neck-head structure.4%%HIGHLIGHT%% ==In our implementation, the process gather and distribute correspond to three modules: FeatureAlignment Module (FAM), Information Fusion Module (IFM), and Information Injection Module(Inject).• The gather process involves two steps. Firstly, the FAM collects and aligns features fromvarious levels. Secondly, IFM fuses the aligned features to generate global information.• Upon obtaining the fused global information from the gather process, the inject moduledistribute this information across each level and injects it using simple attention operations,subsequently enhancing the branch’s detection capability.== %%POSTFIX%%To enhance the model’s ability t*
>%%LINK%%[[#^d57jpdwvuvm|show annotation]]
>%%COMMENT%%
>GD uses 3 modules. 
>Feature Alignment Module (FAM), Information Fusion Module (IFM), and Information INjection Model (inject)
>
>Gathering processes: FAM collects and aligns features from various levels. IFM fueses these aligned featuers to generate global information
>
>Injection module distributes infroation across each level and injects it using attention operations
>%%TAGS%%
>
^d57jpdwvuvm


>%%
>```annotation-json
>{"created":"2025-02-04T05:58:45.370Z","updated":"2025-02-04T05:58:45.370Z","document":{"title":"2309.11331v5.pdf","link":[{"href":"urn:x-pdf:950b1c33809ea8c56afa8e7d6f678701"},{"href":"https://arxiv.org/pdf/2309.11331.pdf"}],"documentFingerprint":"950b1c33809ea8c56afa8e7d6f678701"},"uri":"https://arxiv.org/pdf/2309.11331.pdf","target":[{"source":"https://arxiv.org/pdf/2309.11331.pdf","selector":[{"type":"TextPositionSelector","start":15021,"end":15216},{"type":"TextQuoteSelector","exact":"To enhance the model’s ability to detect objects of varying sizes, we developed two branches: low-stage gather-and-distribute branch (Low-GD) and high-stage gather-and-distribute branch (High-GD)","prefix":"e branch’s detection capability.","suffix":".These branches extract and fuse"}]}]}
>```
>%%
>*%%PREFIX%%e branch’s detection capability.%%HIGHLIGHT%% ==To enhance the model’s ability to detect objects of varying sizes, we developed two branches: low-stage gather-and-distribute branch (Low-GD) and high-stage gather-and-distribute branch (High-GD)== %%POSTFIX%%.These branches extract and fuse*
>%%LINK%%[[#^xhb2g5b8pq|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^xhb2g5b8pq


>%%
>```annotation-json
>{"created":"2025-02-04T06:05:09.146Z","text":"Yolov6-3.0 structure, but replaced neck\n\nEfficeintRep backbone. Efficient Decoupled Head for the head.\n\nSGD with same parameters of YOLOv6.\n\nMosaic and Mixup for training","updated":"2025-02-04T06:05:09.146Z","document":{"title":"2309.11331v5.pdf","link":[{"href":"urn:x-pdf:950b1c33809ea8c56afa8e7d6f678701"},{"href":"https://arxiv.org/pdf/2309.11331.pdf"}],"documentFingerprint":"950b1c33809ea8c56afa8e7d6f678701"},"uri":"https://arxiv.org/pdf/2309.11331.pdf","target":[{"source":"https://arxiv.org/pdf/2309.11331.pdf","selector":[{"type":"TextPositionSelector","start":28965,"end":28988},{"type":"TextQuoteSelector","exact":"Implementation details.","prefix":"oU thresholds and object scales.","suffix":" We followed the setup of YOLOv6"}]}]}
>```
>%%
>*%%PREFIX%%oU thresholds and object scales.%%HIGHLIGHT%% ==Implementation details.== %%POSTFIX%%We followed the setup of YOLOv6*
>%%LINK%%[[#^sg2uzr8tvdc|show annotation]]
>%%COMMENT%%
>Yolov6-3.0 structure, but replaced neck
>
>EfficeintRep backbone. Efficient Decoupled Head for the head.
>
>SGD with same parameters of YOLOv6.
>
>Mosaic and Mixup for training
>%%TAGS%%
>
^sg2uzr8tvdc


>%%
>```annotation-json
>{"created":"2025-02-04T07:39:07.362Z","text":"YOLOv6, but with a neck that uses a special FPN that they denote as Gather-and-Distribute.\n\nThis neck is focuses on feature alignment from each layer, instead of setting up different modules for fusion, its all a part of 1 module that aligns, fuses, and distributes features from each layer to another. \n\nResults are better than most YOLO models up to v8.","updated":"2025-02-04T07:39:07.362Z","document":{"title":"2309.11331v5.pdf","link":[{"href":"urn:x-pdf:950b1c33809ea8c56afa8e7d6f678701"},{"href":"https://arxiv.org/pdf/2309.11331.pdf"}],"documentFingerprint":"950b1c33809ea8c56afa8e7d6f678701"},"uri":"https://arxiv.org/pdf/2309.11331.pdf","target":[{"source":"https://arxiv.org/pdf/2309.11331.pdf","selector":[{"type":"TextPositionSelector","start":0,"end":71},{"type":"TextQuoteSelector","exact":"Gold-YOLO: Efficient Object Detector viaGather-and-Distribute Mechanism","prefix":"th50%75%100%125%150%200%300%400%","suffix":"Chengcheng Wang Wei He Ying Nie "}]}]}
>```
>%%
>*%%PREFIX%%th50%75%100%125%150%200%300%400%%%HIGHLIGHT%% ==Gold-YOLO: Efficient Object Detector viaGather-and-Distribute Mechanism== %%POSTFIX%%Chengcheng Wang Wei He Ying Nie*
>%%LINK%%[[#^v4puq6xwf9|show annotation]]
>%%COMMENT%%
>YOLOv6, but with a neck that uses a special FPN that they denote as Gather-and-Distribute.
>
>This neck is focuses on feature alignment from each layer, instead of setting up different modules for fusion, its all a part of 1 module that aligns, fuses, and distributes features from each layer to another. 
>
>Results are better than most YOLO models up to v8.
>%%TAGS%%
>
^v4puq6xwf9
